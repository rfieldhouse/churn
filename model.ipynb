{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The purpose of this script is to split the transformed feature data into a training and test set\n",
    "# Requires features.p file from features.ipynb\n",
    "# Categorical variables (e.g. tenant_id are encoded)\n",
    "# ...\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "%matplotlib inline\n",
    "import logging\n",
    "import collections\n",
    "import datetime as dt\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.figure \n",
    "import seaborn as sns\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import mysql.connector\n",
    "\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import *\n",
    "# from sklearn.linear_model import *\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors\n",
    "from sklearn import ensemble\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create database engine\n",
    "dbname = 'cs'\n",
    "username = 'rjf'\n",
    "#engine = create_engine('postgresql://rjf@localhost:5432/cs_db')\n",
    "engine = create_engine('mysql+mysqlconnector://mydb_user:rjf@localhost:5432/cs', echo=False)\n",
    "print engine.url\n",
    "\n",
    "passwd = os.environ[\"PASSWD\"]\n",
    "# Connect to database\n",
    "conn = mysql.connector.connect(\n",
    "         user='rjf',\n",
    "         password=passwd,\n",
    "         host='localhost',\n",
    "         database='cs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load features\n",
    "dfFeatures = pickle.load( open( \"features.p\", \"rb\" ) )\n",
    "dfFeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here's an opportunity to subset for particular groups of interest\n",
    "#dfFeatures = dfFeatures[dfFeatures.period_count==1] # clients who have only had one subscription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check for empty values\n",
    "print dfFeatures.info()\n",
    "dfFeatures = dfFeatures.dropna()\n",
    "print dfFeatures.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Assess blance between classes\n",
    "#dfFeatures.churned.unique()\n",
    "print np.sum(dfFeatures.churned==1) # Class 1 churn\n",
    "print np.sum(dfFeatures.churned==0) # Class 0 not churn\n",
    "# Noting here that the classes are imbalanced (6.5% churners, others 93.5% considered engaged for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Fix type of variable\n",
    "# dfFeatures['tenant_id'] = dfFeatures.tenant_id.astype(int)\n",
    "dfFeatures['tenant_id'] = dfFeatures.tenant_id.astype(str)\n",
    "dfFeatures['client_id'] = dfFeatures.client_id.astype(str)\n",
    "\n",
    "dfFeatures['call'] = dfFeatures.call.astype(float)\n",
    "dfFeatures['email'] = dfFeatures.email.astype(float)\n",
    "dfFeatures['meeting'] = dfFeatures.meeting.astype(float)\n",
    "# dfFeatures['call_first'] = dfFeatures.call_first.astype(float)\n",
    "# dfFeatures['email_first'] = dfFeatures.email_first.astype(float)\n",
    "# dfFeatures['meeting_first'] = dfFeatures.meeting_first.astype(float)\n",
    "# dfFeatures['call_last'] = dfFeatures.call_last.astype(float)\n",
    "# dfFeatures['email_last'] = dfFeatures.email_last.astype(float)\n",
    "# dfFeatures['meeting_last'] = dfFeatures.meeting_last.astype(float)\n",
    "\n",
    "dfFeatures['avg_interval'] = dfFeatures.avg_interval.astype(float)\n",
    "dfFeatures['period_duration_sum'] = dfFeatures.period_duration_sum.astype(int)\n",
    "dfFeatures['period_duration_mean'] = dfFeatures.period_duration_sum.astype(int)\n",
    "dfFeatures['period_count'] = dfFeatures.period_count.astype(int)\n",
    "dfFeatures['days_since_last_touch'] = dfFeatures.days_since_last_touch.astype(int)\n",
    "dfFeatures['active_count'] = dfFeatures.active_count.astype(int)\n",
    "dfFeatures['churned'] = dfFeatures.churned.astype(int)\n",
    "dfFeatures.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dfFeatures.ix[3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define data types\n",
    "#y=dfFeatures[['client_id','churned']]\n",
    "y_lbl = dfFeatures['client_id']\n",
    "X_lbl = dfFeatures['tenant_id']\n",
    "y = dfFeatures.churned.as_matrix()\n",
    "#REORDER\n",
    "xlist=['email','call','meeting','email_first','call_first','meeting_first','email_last','call_last','meeting_last','avg_interval','period_duration_sum','period_count']\n",
    "#xlist=('email','call','meeting','email_last','call_last','meeting_last','avg_interval','period_duration_sum','period_count')\n",
    "#xlist=['email_last','call_last','meeting_last','avg_interval','period_duration_sum','period_count']\n",
    "#xlist=['email','call','meeting','avg_interval','days_since_last_touch','period_count','period_duration_sum'] #\n",
    "#xlist=['email','call','meeting','avg_interval','days_since_last_touch','period_duration_sum'] #\n",
    "X = dfFeatures[xlist] #,'active_count']]\n",
    "#X = dfFeatures[['email','call','meeting','email_last','call_last','meeting_last','avg_interval','period_duration_sum','period_count']] #,'active_count']]\n",
    "#X = dfFeatures[['email_last','call_last','meeting_last','avg_interval','period_duration_sum','period_count','days_since_last_touch']] #,'active_count']]\n",
    "#X.set_index('client_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xlen = len(xlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scale data\n",
    "# Tried both MinMaxScaler() and StandardScaler()\n",
    "scaler = MinMaxScaler() #StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "dfFeaturesScaled = pd.DataFrame(X_scaled,columns=xlist)#,'active_count'])\n",
    "#dfFeaturesScaled = pd.DataFrame(X_scaled,columns=['email','call','meeting','email_last','call_last','meeting_last','avg_interval','period_duration_sum','period_count'])#,'active_count'])\n",
    "#dfFeaturesScaled = pd.DataFrame(X_scaled,columns=['email_last','call_last','meeting_last','avg_interval','period_duration_sum','period_count','days_since_last_touch'])#,'active_count'])\n",
    "dfFeaturesScaled['churned'] = y\n",
    "dfFeaturesScaled['tenant_id'] = X_lbl\n",
    "dfFeaturesScaled['client_id'] = y_lbl\n",
    "dfFeaturesScaled = dfFeaturesScaled.dropna()\n",
    "dfFeatures['tenant_id'] = dfFeatures.tenant_id.astype(str)\n",
    "dfFeatures['client_id'] = dfFeatures.client_id.astype(str)\n",
    "#dfFeaturesScaled.head()\n",
    "y = dfFeaturesScaled.churned.as_matrix()\n",
    "X = dfFeaturesScaled[xlist] #,'active_count']]\n",
    "#X = dfFeaturesScaled[['email','call','meeting','email_last','call_last','meeting_last','avg_interval','period_duration_sum','period_count','tenant_id']] #,'active_count']]\n",
    "#X = dfFeaturesScaled[['email_last','call_last','meeting_last','avg_interval','period_duration_sum','period_count','days_since_last_touch','tenant_id']] #,'active_count']]\n",
    "X_original=X\n",
    "y_original=y\n",
    "y_original_lbl=dfFeaturesScaled.client_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X=X.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Split data into test set and training set\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'X'\n",
    "print X\n",
    "print\n",
    "print 'y'\n",
    "print y\n",
    "print\n",
    "print 'X_train'\n",
    "print X_train\n",
    "print\n",
    "print 'X_test'\n",
    "print X_test\n",
    "print\n",
    "print 'y_train'\n",
    "print y_train\n",
    "print\n",
    "print 'y_test'\n",
    "print y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check sizes of test and training set\n",
    "print 'X_train'\n",
    "print X_train.shape\n",
    "print 'X_test'\n",
    "print X_test.shape\n",
    "print 'y_train'\n",
    "print y_train.shape\n",
    "print 'y_test'\n",
    "print y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Encode categoricals\n",
    "enc = OneHotEncoder(categorical_features=[0,])\n",
    "X_enc = enc.fit(X)\n",
    "X_train_enc = enc.transform(X_train)\n",
    "X_test_enc = enc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Several options make sense for modeling, including logistic regression, linear support vector classifier, \n",
    "# K-nearest neighbors, and random forest\n",
    "\n",
    "clf = linear_model.LogisticRegressionCV(cv=10,class_weight='balanced') #,penalty='l1',solver='liblinear')\n",
    "#clf = svm.LinearSVC(class_weight='balanced')\n",
    "#clf = neighbors.KNeighborsClassifier() #NO CLASS WEIGHT\n",
    "#clf = ensemble.RandomForestClassifier(class_weight='balanced') # n_estimators=15,\n",
    "\n",
    "\n",
    "# Pipeline methods can be used to bundle feature selection process and classification\n",
    "# clf = Pipeline([\n",
    "#   ('feature_selection', SelectFromModel(linear_model.LogisticRegressionCV(cv=5,class_weight='balanced',penalty='l2'))),\n",
    "#   ('classification', svm.LinearSVC(class_weight='balanced'))\n",
    "# ])\n",
    "\n",
    "# clf = Pipeline([\n",
    "#   ('feature_selection', SelectFromModel(linear_model.LogisticRegressionCV(cv=5,class_weight='balanced',penalty='l2'))),\n",
    "#   ('classification', ensemble.RandomForestClassifier(n_estimators=15,class_weight='balanced'))\n",
    "# ])\n",
    "\n",
    "def train_and_evaluate(clf, X_train, y_train):\n",
    "    clf.fit(X_train,y_train)\n",
    "    #sample weight available for LogisticRegressionCV, linearSVC, RandomForestClassifier\n",
    "    #cv = KFold(n_splits=5,shuffle=True,random_state=None)\n",
    "    scores = cross_val_score(clf, X_train, y_train) #,cv=cv)\n",
    "\n",
    "    return clf\n",
    "\n",
    "#scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Testing and evaluation\n",
    "\n",
    "global y_decision_function\n",
    "global y_predict_proba\n",
    "global y_predict\n",
    "global y_score\n",
    "def TestAndEvaluate(X_test, y_test, clf):\n",
    "    try:\n",
    "        y_decision_function = clf.decision_function(X_test) #Regression, linearSVC\n",
    "        print 'y_decision_function'\n",
    "        print y_decision_function  \n",
    "        \n",
    "        y_ret = y_decision_function\n",
    "    except Exception as err:\n",
    "        logging.exception(err)\n",
    "    \n",
    "    try:\n",
    "        y_predict_proba = clf.predict_proba(X_test)[:,1] #KNeighborsSVC, Random forest\n",
    "        print 'y_predict_proba'\n",
    "        print y_predict_proba\n",
    "        \n",
    "        y_ret = y_predict_proba\n",
    "    except Exception as err:\n",
    "        logging.exception(err)\n",
    "\n",
    "    try:\n",
    "        y_predict = clf.predict(X_test) #[:,1]\n",
    "        print 'y_predict'\n",
    "        print y_predict\n",
    "        \n",
    "        y_ret = y_predict\n",
    "    except Exception as err:\n",
    "        logging.exception(err)\n",
    "\n",
    "    try:\n",
    "        y_score = clf.score(X_test,y_test) #[:,1]\n",
    "        print 'y_score'\n",
    "        print y_score\n",
    "        \n",
    "        y_ret = y_score\n",
    "    except Exception as err:\n",
    "        logging.exception(err)\n",
    "\n",
    "    try:\n",
    "        fpr, tpr, _ = metrics.roc_curve(y_test, y_decision_function)\n",
    "    except Exception as err:\n",
    "        logging.exception(err)\n",
    "\n",
    "    try:\n",
    "        fpr, tpr, _ = metrics.roc_curve(y_test, y_predict_proba)\n",
    "    except Exception as err:\n",
    "        logging.exception(err)\n",
    "\n",
    "    try:\n",
    "        roc_auc = metrics.auc(fpr,tpr)   \n",
    "        plt.figure()\n",
    "        lw = 2\n",
    "        plt.plot(fpr, tpr, color='darkorange',lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver operating characteristic')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.savefig('auc.png')\n",
    "        plt.close()\n",
    "    except Exception as err:\n",
    "        logging.exception(err)\n",
    "\n",
    "    try:\n",
    "        features = SelectFromModel(clf,prefit=True)\n",
    "        print features\n",
    "    except Exception as err:\n",
    "        logging.exception(err)\n",
    "        \n",
    "    try: # Attribute not available for all types of classifiers\n",
    "        print 'Feature importances'\n",
    "        print clf.feature_importances_\n",
    "    except Exception as err:\n",
    "        logging.exception(err)\n",
    "\n",
    "    try: # Attribute not available for all types of classifiers\n",
    "        print 'coef'\n",
    "        print clf.coef_\n",
    "    except Exception as err:\n",
    "        logging.exception(err)\n",
    "    \n",
    "    return y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "\n",
    "def matrix_and_pars(ytest,ypred):\n",
    "    cm = confusion_matrix(ytest,ypred)\n",
    "    precision = float(cm[0][0]) / (cm[0][0]+cm[1][0])\n",
    "    recall = float(cm[0][0]) / (cm[0][0]+cm[0][1])\n",
    "    F1 = 2*precision*recall/(recall+precision)\n",
    "    print 'recall: %0.3f precision: %0.3f F1: %0.3f' %(recall,precision,F1)\n",
    "    print '%d %d' %(cm[0][0],cm[0][1])\n",
    "    print '%d %d' %(cm[1][0],cm[1][1])\n",
    "    plot_confusion_matrix(cm)\n",
    "    classes=['engaged','churned']\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_names = np.unique(y_test)\n",
    "#print class_names\n",
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:,np.newaxis]\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(2)\n",
    "    plt.xticks(tick_marks)\n",
    "    plt.yticks(tick_marks)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.grid(False)\n",
    "    plt.savefig('cm.png')\n",
    "    plt.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "train_and_evaluate(clf,X_train_enc,y_train) #X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test model\n",
    "#y_pred = measure_performance(X_test_enc, y_test, clf)\n",
    "y_pred = TestAndEvaluate(X_test_enc, y_test, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "\n",
    "matrix_and_pars(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print X.shape\n",
    "print y.shape\n",
    "print X_train.shape\n",
    "print y_train.shape\n",
    "print X_test.shape\n",
    "print y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sfm\n",
    "importances = list(clf.coef_[0,:xlen])\n",
    "print importances\n",
    "print 'x len'\n",
    "print len(importances)\n",
    "importances = [abs(number) for number in importances]\n",
    "\n",
    "\n",
    "xlbls=range(xlen) #[0,1,2,3,4,5]\n",
    "print 'x lbl length'\n",
    "print len(xlbls)\n",
    "\n",
    "#xlist=('email','call','meeting','email_last','call_last','meeting_last','avg_interval','period_duration_sum','period_count')\n",
    "#xlist=('email_last','call_last','meeting_last','avg_interval','period_duration_sum','period_count')\n",
    "#xlist=['n_emails','n_calls','n_meetings','frequency','recency','relationship length']\n",
    "#print len(xlist)\n",
    "\n",
    "x_list = ('email frequency','call frequency','meeting frequency',\\\n",
    "          'email frequency (early)','call frequency (early)','meeting frequency (early)',\\\n",
    "          'email frequency (late)','call frequency (late)','meeting frequency (late)',\\\n",
    "          'mean interval', 'length of relationship','number of subscription periods')\n",
    "\n",
    "#plt.xticks(rotation=45) #'vertical')\n",
    "plt.figure()\n",
    "plt.barh(xlbls,importances,tick_label=x_list) #,rotation=45)\n",
    "plt.savefig('features.png')\n",
    "plt.close()\n",
    "#xlbls=[0,1,2,3,4,5,6]\n",
    "#plt.bar(xlbls,importances,tick_label=('email_last','call_last','meeting_last','avg_interval','period_duration_sum','period_count','days_since_last_touch')) #,rotation=45)\n",
    "\n",
    "#print len(importances)\n",
    "#importances = pd.DataFrame(importances)\n",
    "#print importances\n",
    "#plt.bar([1,2,3,4,5,6],importances)\n",
    "#fig, ax = plt.subplots()\n",
    "#ax.bar(importances)\n",
    "#ax.set_xticklabels(()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "scores, pvalues = chi2(X, y)\n",
    "scores\n",
    "pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfe = RFE(clf, 3)\n",
    "rfe.fit(X_train,y_train)\n",
    "print rfe.support_\n",
    "print rfe.ranking_\n",
    "print range(1,10)\n",
    "print xlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Run on all data (for web app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_all=enc.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_predict = clf.predict(X_all)\n",
    "y_predict_proba = clf.predict_proba(X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfYOriginalLbl = pd.DataFrame(y_original_lbl).reset_index()\n",
    "dfYOriginal = pd.DataFrame(y_original).reset_index()\n",
    "dfOriginal = X_original.reset_index()\n",
    "\n",
    "dfYPredict = pd.DataFrame(y_predict)\n",
    "dfYPredict = dfYPredict.rename(columns={0:'churn_pred'})\n",
    "\n",
    "dfYPredictProba = pd.DataFrame(y_predict_proba)\n",
    "dfYPredictProba = dfYPredictProba.rename(columns={0:'churn_no'})\n",
    "dfYPredictProba = dfYPredictProba.rename(columns={1:'churn_yes'})\n",
    "\n",
    "dfResult = dfYPredictProba.join(dfYPredict)\n",
    "dfResult = dfOriginal.join(dfResult)\n",
    "dfResult = pd.merge(dfYOriginalLbl,dfResult)\n",
    "dfResult = pd.merge(dfResult,dfYOriginal)\n",
    "dfResult = dfResult.rename(columns={0:'churn_actual'})\n",
    "dfResult = dfResult.drop('index',axis=1)\n",
    "dfResult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(dfResult, open( \"results.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dfYOriginalLbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfResult = pd.merge(dfYOriginalLbl,dfFeatures)\n",
    "dfResult = dfResult.join(dfYPredictProba)\n",
    "dfResult = dfResult.join(dfYPredict)\n",
    "dfResult = dfResult.rename(columns={0:'churn_actual'})\n",
    "dfResult = dfResult.drop('index',axis=1)\n",
    "dfResult = dfResult.dropna()\n",
    "dfResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(dfResult, open( \"results.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfResult.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfResult.to_csv('results.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
