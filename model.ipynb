{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Model\n",
    "\n",
    "The purpose of this script is to model churn based on engineered features\n",
    "split the transformed feature data into a training and test set\n",
    "\n",
    "Run this script after feature.ipynb\n",
    "\n",
    "Requires features.p file from features.ipynb\n",
    "Produces results.p and results.tsv\n",
    "\n",
    "Features are \n",
    "\n",
    "Scaling is performed using MinMaxScaler\n",
    "\n",
    "Categorical variables (e.g. tenant_id are encoded using OneHotEncoder)\n",
    "\n",
    "Train_test_split was used to split the data into a training set and testing set\n",
    "\n",
    "Several modeling approaches are tried including \\\n",
    "LogisticRegression, LinearSVC, KNeighborsClassifier, RandomForestClassifier\n",
    "\n",
    "Cross-validation was performed (usually using built-in settings of the modeling object)\n",
    "\n",
    "Evaluation was done using confusion matrix, ROC curve (and AUC metric)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "%matplotlib inline\n",
    "import logging\n",
    "import collections\n",
    "import datetime as dt\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.figure \n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.svm import *\n",
    "from sklearn.neighbors import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "\n",
    "Note data cleaning was done in previous scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load features\n",
    "# dfFeatures = pickle.load( open( \"features_all.p\", \"rb\" ) )\n",
    "dfFeatures = pickle.load( open( \"combined_features.p\", \"rb\" ) )\n",
    "dfFeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(dfFeatures.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here's an opportunity to subset for particular groups of interest\n",
    "#dfFeatures = dfFeatures[dfFeatures.period_count==1] # clients who have only had one subscription\n",
    "#dfFeatures = dfFeatures[dfFeatures.num_periods==1] # clients who have only had one subscription"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data cleaning (double check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check for empty values\n",
    "print dfFeatures.info()\n",
    "dfFeatures = dfFeatures.dropna()\n",
    "print dfFeatures.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfFeatures.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfFeatures.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfFeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dfFeatures.ix[3,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assess Class Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Assess balance between classes\n",
    "#dfFeatures.churned.unique()\n",
    "churnedCount = np.sum(dfFeatures.churned==1) # Class 1 churn\n",
    "engagedCount = np.sum(dfFeatures.churned==0) # Class 0 not churn\n",
    "print churnedCount\n",
    "print engagedCount\n",
    "print str(round((float(churnedCount)/float(churnedCount+engagedCount))*100,1)) + '%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scale data\n",
    "scaler = MinMaxScaler() # Also tried StandardScaler()\n",
    "# without categoricals\n",
    "masterList = [\n",
    "#  'tenant_id',\n",
    " 'num_days',\n",
    "#  'num_interactions',\n",
    "#  'num_emails',\n",
    "#  'num_calls',\n",
    "#  'num_meetings',\n",
    " 'mean_gap',\n",
    "#  'max_gap',\n",
    "#  'min_gap',\n",
    "#  'frequency',\n",
    " 'email_frequency',\n",
    " 'call_frequency',\n",
    " 'meeting_frequency',\n",
    "#  'num_periods',\n",
    "#  'mean_duration',\n",
    "#  'total_duration',\n",
    "#  'min_duration',\n",
    "#  'max_duration',\n",
    " 'recency',\n",
    "#  'churned'\n",
    "]\n",
    "\n",
    "# with categoricals\n",
    "masterListPlus = [\n",
    " 'tenant_id',\n",
    " 'client_id',\n",
    " 'num_days',\n",
    "#  'num_interactions',\n",
    "#  'num_emails',\n",
    "#  'num_calls',\n",
    "#  'num_meetings',\n",
    " 'mean_gap',\n",
    "#  'max_gap',\n",
    "#  'min_gap',\n",
    "#  'frequency',\n",
    " 'email_frequency',\n",
    " 'call_frequency',\n",
    " 'meeting_frequency',\n",
    "#  'num_periods',\n",
    "#  'mean_duration',\n",
    "#  'total_duration',\n",
    "#  'min_duration',\n",
    "#  'max_duration',\n",
    " 'recency',\n",
    " 'churned'\n",
    "]\n",
    "\n",
    "features = dfFeatures[masterList].as_matrix()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "dfFeaturesScaled = pd.DataFrame(features_scaled,columns=masterList)\n",
    "dfFeaturesScaled['tenant_id'] = dfFeatures['tenant_id']\n",
    "dfFeaturesScaled['client_id'] = dfFeatures['client_id']\n",
    "dfFeaturesScaled['churned'] = dfFeatures['churned']\n",
    "dfFeaturesScaled = dfFeaturesScaled[masterListPlus]\n",
    "dfFeaturesScaled = dfFeaturesScaled.dropna()\n",
    "featuresScaled = dfFeaturesScaled.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define feature list\n",
    "ylist = [\n",
    "    'client_id',\n",
    "    'churned'\n",
    "]\n",
    "\n",
    "#Different variations possible for features used\n",
    "#... agg, first & last\n",
    "#xlist=['email','call','meeting','email_first','call_first','meeting_first','email_last','call_last','meeting_last','avg_interval','period_duration_sum','period_count']\n",
    "\n",
    "# agg & last\n",
    "#xlist=['email','call','meeting','email_last','call_last','meeting_last','avg_interval','period_duration_sum','period_count']\n",
    "\n",
    "# just last\n",
    "#xlist=['email_last','call_last','meeting_last','avg_interval','period_duration_sum','period_count']\n",
    "\n",
    "# just agg\n",
    "#xlist=['email','call','meeting','avg_interval','days_since_last_touch','period_count','period_duration_sum']\n",
    "\n",
    "# just agg w no period duration sum\n",
    "#xlist=['email','call','meeting','avg_interval','days_since_last_touch','period_duration_sum']\n",
    "\n",
    "# just agg\n",
    "#xlist=['email','call','meeting','avg_interval','period_duration_sum','period_duration_mean','period_count']\n",
    "\n",
    "#xlist=['email','call','meeting','email_first','call_first','meeting_first','email_last','call_last','meeting_last','avg_interval','period_duration_sum','period_count','days_since_last_touch']\n",
    "\n",
    "xlist=[\n",
    " 'tenant_id',\n",
    "#  'client_id',\n",
    " 'num_days',\n",
    "#  'num_interactions',\n",
    "#  'num_emails',\n",
    "#  'num_calls',\n",
    "#  'num_meetings',\n",
    " 'mean_gap',\n",
    "#  'max_gap',\n",
    "#  'min_gap',\n",
    "#  'frequency',\n",
    " 'email_frequency',\n",
    " 'call_frequency',\n",
    " 'meeting_frequency',\n",
    "#  'num_periods',\n",
    "#  'mean_duration',\n",
    "#  'total_duration',\n",
    "#  'min_duration',\n",
    "#  'max_duration',\n",
    "#  'active_count',\n",
    " 'recency',\n",
    "#  'churned'\n",
    "]\n",
    "\n",
    "Y_lbl = dfFeaturesScaled['client_id']\n",
    "dfY = dfFeaturesScaled['churned']\n",
    "y = dfFeaturesScaled['churned'].as_matrix()\n",
    "\n",
    "X_lbl = dfFeaturesScaled['tenant_id']\n",
    "dfX = dfFeaturesScaled[xlist]\n",
    "X = dfX.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfX.head()\n",
    "dfX.describe()\n",
    "dfX.info()\n",
    "dfY.head()\n",
    "X\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Split data into test set and training set\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Show contents of raw data, training set and test set\n",
    "print 'X'\n",
    "print X\n",
    "print\n",
    "print 'y'\n",
    "print y\n",
    "print\n",
    "print 'X_train'\n",
    "print X_train\n",
    "print\n",
    "print 'X_test'\n",
    "print X_test\n",
    "print\n",
    "print 'y_train'\n",
    "print y_train\n",
    "print\n",
    "print 'y_test'\n",
    "print y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Check sizes of raw data, training set and test set\n",
    "print 'X'\n",
    "print X.shape\n",
    "print 'y'\n",
    "print y.shape\n",
    "print 'X_train'\n",
    "print X_train.shape\n",
    "print 'X_test'\n",
    "print X_test.shape\n",
    "print 'y_train'\n",
    "print y_train.shape\n",
    "print 'y_test'\n",
    "print y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfX = pd.DataFrame(X,columns=xlist)\n",
    "dfY = pd.DataFrame(y,columns=['churned',])\n",
    "dfXTrain = pd.DataFrame(X_train,columns=xlist)\n",
    "dfYTrain = pd.DataFrame(y_train,columns=['churned',])\n",
    "dfXTest = pd.DataFrame(X_test,columns=xlist)\n",
    "dfYTest = pd.DataFrame(y_test,columns=['churned',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfX = dfX[xlist][1:-1].apply(pd.to_numeric)\n",
    "dfXTrain = dfXTrain[xlist][1:-1].apply(pd.to_numeric)\n",
    "dfXTest = dfXTest[xlist][1:-1].apply(pd.to_numeric)\n",
    "dfX['tenant_id'] = dfX['tenant_id'].astype(str)\n",
    "dfXTrain['tenant_id'] = dfXTrain['tenant_id'].astype(str)\n",
    "dfXTest['tenant_id'] = dfXTest['tenant_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print dfX.head()\n",
    "# print\n",
    "# print dfY.head()\n",
    "# print\n",
    "# print dfXTrain.head()\n",
    "# print\n",
    "# print dfXTest.head()\n",
    "# print\n",
    "# print dfYTrain.head()\n",
    "# print\n",
    "# print dfYTest.head()\n",
    "# print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dfX.info()\n",
    "# print\n",
    "# dfY.info()\n",
    "# print\n",
    "# dfXTrain.info()\n",
    "# print\n",
    "# dfYTrain.info()\n",
    "# print\n",
    "# dfXTest.info()\n",
    "# print\n",
    "# dfYTest.info()\n",
    "# print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Feature correlation\n",
    "ax = sns.heatmap(dfXTrain.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Chi-squared statistic on feature importance\n",
    "scores, pvalues = chi2(X_train, y_train)\n",
    "print scores\n",
    "print pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Recursive feature elimination\n",
    "clf = LogisticRegressionCV(cv=5,class_weight='balanced')\n",
    "rfe = RFE(clf, 1)\n",
    "rfe.fit(X_train,y_train)\n",
    "#print range(0,len(xlist))\n",
    "#print xlist\n",
    "#print rfe.support_\n",
    "#print rfe.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfFeatureSelection = pd.DataFrame({'feature':xlist,'score':scores,'p-value':pvalues,'rank':rfe.ranking_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfFeatureSelectionSig = dfFeatureSelection[dfFeatureSelection['p-value']>0.05]\n",
    "dfFeatureSelectionSig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfFeatureSelectionRank = dfFeatureSelection.sort_values('rank',ascending=True)\n",
    "dfFeatureSelectionRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfFeatureSelectionCombo = dfFeatureSelection[dfFeatureSelection['p-value']>0.05]\n",
    "dfFeatureSelectionCombo = dfFeatureSelectionCombo.sort_values('rank',ascending=True)\n",
    "dfFeatureSelectionCombo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Check sizes of raw data, training set and test set\n",
    "print 'X'\n",
    "print X.shape\n",
    "print 'X_train'\n",
    "print X_train.shape\n",
    "print 'X_test'\n",
    "print X_test.shape\n",
    "print 'y'\n",
    "print y.shape\n",
    "print 'y_train'\n",
    "print y_train.shape\n",
    "print 'y_test'\n",
    "print y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xlistReduced=[\n",
    " 'tenant_id',\n",
    " 'num_days',\n",
    "#  'num_interactions',\n",
    " 'num_emails',\n",
    " 'num_calls',\n",
    " 'num_meetings',\n",
    " 'mean_gap',\n",
    "#  'max_gap',\n",
    "#  'min_gap',\n",
    "#  'frequency',\n",
    " 'email_frequency',\n",
    " 'call_frequency',\n",
    " 'meeting_frequency',\n",
    " 'num_periods',\n",
    "#  'mean_duration',\n",
    "#  'total_duration',\n",
    "#  'min_duration',\n",
    "#  'max_duration'\n",
    " 'recency'\n",
    "]\n",
    "# dfX = dfX[xlistReduced]\n",
    "# dfXTrain = dfXTrain[xlistReduced]\n",
    "# dfXTest = dfXTest[xlistReduced]\n",
    "\n",
    "# X = dfX.as_matrix()\n",
    "# X_train = dfXTrain.as_matrix()\n",
    "# X_test = dfXTest.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Check sizes of raw data, training set and test set\n",
    "print 'X'\n",
    "print X.shape\n",
    "print 'X_train'\n",
    "print X_train.shape\n",
    "print 'X_test'\n",
    "print X_test.shape\n",
    "print 'y'\n",
    "print y.shape\n",
    "print 'y_train'\n",
    "print y_train.shape\n",
    "print 'y_test'\n",
    "print y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode Categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encode categoricals\n",
    "enc = OneHotEncoder(categorical_features=[0,])\n",
    "X_enc = enc.fit(X)\n",
    "X_train_enc = enc.transform(X_train)\n",
    "X_test_enc = enc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Several options make sense for modeling, including logistic regression, linear support vector classifier, \n",
    "# K-nearest neighbors, and random forest\n",
    "\n",
    "clf = LogisticRegressionCV(cv=5,class_weight='balanced') #,penalty='l1',solver='liblinear')\n",
    "#clf = LinearSVC(class_weight='balanced')\n",
    "#clf = KNeighborsClassifier() #NO CLASS WEIGHT\n",
    "#clf = RandomForestClassifier(class_weight='balanced') # n_estimators=15,\n",
    "\n",
    "\n",
    "# Pipeline methods can be used to bundle feature selection process and classification\n",
    "# clf = Pipeline([\n",
    "#   ('feature_selection', SelectFromModel(linear_model.LogisticRegressionCV(cv=5,class_weight='balanced',penalty='l2'))),\n",
    "#   ('classification', svm.LinearSVC(class_weight='balanced'))\n",
    "# ])\n",
    "\n",
    "# clf = Pipeline([\n",
    "#   ('feature_selection', SelectFromModel(linear_model.LogisticRegressionCV(cv=5,class_weight='balanced',penalty='l2'))),\n",
    "#   ('classification', ensemble.RandomForestClassifier(n_estimators=15,class_weight='balanced'))\n",
    "# ])\n",
    "\n",
    "def train_and_evaluate(clf, X_train, y_train):\n",
    "    clf.fit(X_train,y_train)\n",
    "    #sample weight available for LogisticRegressionCV, linearSVC, RandomForestClassifier\n",
    "    #cv = KFold(n_splits=5,shuffle=True,random_state=None)\n",
    "    scores = cross_val_score(clf, X_train, y_train) #,cv=cv)\n",
    "\n",
    "    return clf\n",
    "\n",
    "#scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "train_and_evaluate(clf,X_train_enc,y_train) #X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Performance on a Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Testing and evaluation # including ROC curve\n",
    "\n",
    "global y_decision_function\n",
    "global y_predict_proba\n",
    "global y_predict\n",
    "global y_score\n",
    "def TestAndEvaluate(X_test, y_test, clf):\n",
    "    try:\n",
    "        y_decision_function = clf.decision_function(X_test) #Regression, linearSVC\n",
    "        print 'y_decision_function'\n",
    "        print y_decision_function  \n",
    "        \n",
    "        y_ret = y_decision_function\n",
    "    except Exception as err:\n",
    "        logging.exception(err)\n",
    "    \n",
    "    try:\n",
    "        y_predict_proba = clf.predict_proba(X_test)[:,1] #KNeighborsSVC, Random forest\n",
    "        print 'y_predict_proba'\n",
    "        print y_predict_proba\n",
    "        \n",
    "        y_ret = y_predict_proba\n",
    "    except Exception as err:\n",
    "        logging.exception(err)\n",
    "\n",
    "    try:\n",
    "        y_predict = clf.predict(X_test) #[:,1]\n",
    "        print 'y_predict'\n",
    "        print y_predict\n",
    "        \n",
    "        y_ret = y_predict\n",
    "    except Exception as err:\n",
    "        logging.exception(err)\n",
    "\n",
    "    try:\n",
    "        y_score = clf.score(X_test,y_test) #[:,1]\n",
    "        print 'y_score'\n",
    "        print y_score\n",
    "        \n",
    "        y_ret = y_score\n",
    "    except Exception as err:\n",
    "        logging.exception(err)\n",
    "\n",
    "    try:\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_decision_function)\n",
    "    except Exception as err:\n",
    "        logging.exception(err)\n",
    "\n",
    "    try:\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_predict_proba)\n",
    "    except Exception as err:\n",
    "        logging.exception(err)\n",
    "\n",
    "    try:\n",
    "        roc_auc = auc(fpr,tpr)   \n",
    "        plt.figure()\n",
    "        lw = 2\n",
    "        plt.plot(fpr, tpr, color='darkorange',lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver operating characteristic')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.savefig('auc.png')\n",
    "        plt.close()\n",
    "    except Exception as err:\n",
    "        logging.exception(err)\n",
    "\n",
    "    try:\n",
    "        features = SelectFromModel(clf,prefit=True)\n",
    "        print features\n",
    "    except Exception as err:\n",
    "        logging.exception(err)\n",
    "        \n",
    "    try: # Attribute not available for all types of classifiers\n",
    "        print 'Feature importances'\n",
    "        print clf.feature_importances_\n",
    "    except Exception as err:\n",
    "        logging.exception(err)\n",
    "\n",
    "    try: # Attribute not available for all types of classifiers\n",
    "        print 'coef'\n",
    "        print clf.coef_\n",
    "    except Exception as err:\n",
    "        logging.exception(err)\n",
    "    \n",
    "    return y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    print 'plot_confusion_matrix'\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:,np.newaxis]\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(2)\n",
    "    classes=['engaged','churned']\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks)\n",
    "    plt.yticks(tick_marks)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.grid(False)\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    plt.savefig('cm.png')\n",
    "    plt.close()\n",
    "    return\n",
    "\n",
    "def matrix_and_pars(ytest,ypred):\n",
    "    print 'matrix_and_pars'\n",
    "    cm = confusion_matrix(ytest,ypred)\n",
    "    precision = float(cm[0][0]) / (cm[0][0]+cm[1][0])\n",
    "    recall = float(cm[0][0]) / (cm[0][0]+cm[0][1])\n",
    "    F1 = 2*precision*recall/(recall+precision)\n",
    "    print 'recall: %0.3f precision: %0.3f F1: %0.3f' %(recall,precision,F1)\n",
    "    print '%d %d' %(cm[0][0],cm[0][1])\n",
    "    print '%d %d' %(cm[1][0],cm[1][1])\n",
    "    plot_confusion_matrix(cm)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#y_pred = measure_performance(X_test_enc, y_test, clf)\n",
    "y_pred = TestAndEvaluate(X_test_enc, y_test, clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "matrix_and_pars(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Feature importances plot\n",
    "def FeatureImportances(clf):\n",
    "    importances = list(clf.coef_[0,:xlen])\n",
    "    importances = [abs(number) for number in importances]\n",
    "    xlbls=range(xlen)\n",
    "    print xlbls #numbers\n",
    "    print xlist #names\n",
    "    print importances\n",
    "    plt.barh(xlbls,importances,tick_label=xlist, align='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xlist = [x.replace('tenant_id', 'tenant') for x in xlist]\n",
    "xlist = [x.replace('num_days', 'relationship length') for x in xlist]\n",
    "xlist = [x.replace('email_frequency', 'email frequency') for x in xlist]\n",
    "xlist = [x.replace('call_frequency', 'call frequency') for x in xlist]\n",
    "xlist = [x.replace('meeting_frequency', 'meeting frequency') for x in xlist]\n",
    "xlist = [x.replace('mean_gap', 'gap (avg)') for x in xlist]\n",
    "xlist = [x.replace('max_gap', 'gap (max)') for x in xlist]\n",
    "xlist = [x.replace('mean_duration', 'subscription duration') for x in xlist]\n",
    "xlen = len(xlist)\n",
    "FeatureImportances(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output of data for dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Run on all data (for dashboard)\n",
    "X_all=enc.transform(X)\n",
    "y_predict = clf.predict(X_all)\n",
    "y_predict_proba = clf.predict_proba(X_all)\n",
    "dfYLbl = pd.DataFrame(Y_lbl).reset_index()\n",
    "dfY = pd.DataFrame(dfY).reset_index()\n",
    "dfX = dfX.reset_index()\n",
    "dfYPredict = pd.DataFrame(y_predict)\n",
    "dfYPredict = dfYPredict.rename(columns={0:'churn_pred'})\n",
    "dfYPredictProba = pd.DataFrame(y_predict_proba)\n",
    "dfYPredictProba = dfYPredictProba.rename(columns={0:'churn_no'})\n",
    "dfYPredictProba = dfYPredictProba.rename(columns={1:'churn_yes'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfResult = dfYPredictProba.join(dfYPredict)\n",
    "dfResult = dfFeaturesScaled.join(dfResult)\n",
    "dfResult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfResult.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfResult.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(dfResult, open( \"results.p\", \"wb\" ))\n",
    "dfResult.to_csv('results.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfResult = dfYPredictProba.join(dfYPredict)\n",
    "dfResult = dfFeatures.join(dfResult)\n",
    "dfResult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfResult.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfResult.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(dfResult, open( \"results_int.p\", \"wb\" ))\n",
    "dfResult.to_csv('results_int.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The likelihood of churn is driven by the total duration of the relationship more than other factors and, while predictions based on this feature are reliable, cadence of communication remains challenging area for exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
